# Daniel Lee LLM Questions

What 𝗟𝗟𝗠 𝗰𝗼𝗻𝗰𝗲𝗽𝘁𝘀 are often asked in 𝗟𝗟𝗠/𝗠𝗟 𝗘𝗻𝗴𝗶𝗻𝗲𝗲𝗿 𝗶𝗻𝘁𝗲𝗿𝘃𝗶𝗲𝘄?

Here’s a list asked in Google, Nvidia, Meta, Intuit and Adobe are ↓

𝗔𝗿𝗰𝗵𝗶𝘁𝗲𝗰𝘁𝘂𝗿𝗲 & 𝗧𝗿𝗮𝗶𝗻𝗶𝗻𝗴
• Transformer Architecture (attention mechanisms
• Pre-training vs Fine-tuning
• Training Objectives (next token prediction)
• Context Window and Position Embeddings
• Tokenization Strategies
• Model Scaling Laws
• Parameter Efficient Fine-tuning (LoRA, QLoRA, Prefix Tuning)

𝗚𝗲𝗻𝗲𝗿𝗮𝘁𝗶𝗼𝗻 𝗖𝗼𝗻𝘁𝗿𝗼𝗹
• Temperature and Top-p Sampling
• Prompt Engineering Techniques
• Few-shot Learning
• In-context Learning
• Chain-of-Thought Prompting
• Hallucination Prevention

𝗟𝗟𝗠 𝗘𝘃𝗮𝗹𝘂𝗮𝘁𝗶𝗼𝗻
• Perplexity
• ROUGE Scores
• BLEU Scores
• Human Evaluation Methods
• Benchmark Datasets (MMLU, BigBench, HumanEval)
• Bias Detection

𝗢𝗽𝘁𝗶𝗺𝗶𝘇𝗮𝘁𝗶𝗼𝗻 & 𝗗𝗲𝗽𝗹𝗼𝘆𝗺𝗲𝗻𝘁
• Quantization Techniques (4-bit, 8-bit)
• Model Distillation
• Prompt Caching
• Model Merging
• Inference Optimization
• Load Balancing
• Latency Management
• Cost Optimization

𝗦𝗮𝗳𝗲𝘁𝘆 & 𝗘𝘁𝗵𝗶𝗰𝘀
• Content Filtering
• Output Sanitization
• Jailbreak Prevention
• Data Privacy

Other areas covered in LLM Engineer or ML Engineer, Gen AI roles include system design, coding and ML depth.

⤷ What's another concept asked in LLM interviews? Drop one ↓
Ace upcoming interviews with these👇

📕 𝗜𝗻𝘁𝗲𝗿𝘃𝗶𝗲𝘄 𝗣𝗿𝗲𝗽 𝗖𝗼𝘂𝗿𝘀𝗲𝘀: datainterview.com/courses
📘 𝗝𝗼𝗶𝗻 𝗗𝗦 𝗜𝗻𝘁𝗲𝗿𝘃𝗶𝗲𝘄 𝗕𝗼𝗼𝘁𝗰𝗮𝗺𝗽: https://lnkd.in/egCcmuCr
📙 𝗝𝗼𝗶𝗻 𝗠𝗟𝗘 𝗜𝗻𝘁𝗲𝗿𝘃𝗶𝗲𝘄 𝗕𝗼𝗼𝘁𝗰𝗮𝗺𝗽: https://lnkd.in/e5VaYyTz
